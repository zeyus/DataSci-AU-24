{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 5 - Bagging and Boosting\n",
    "\n",
    "### Recap of lecture and introductory remarks\n",
    "In yesterday's lecture, we introduced bagging and boosting as two techniques to reduce variance and reduce variance of decision trees. Bagging and boosting are not specific to decision trees, but we will see them in action with this kind of model.\n",
    "\n",
    "We used bagging to train a set of small decision trees (weak learners) on subsets of the training data, whose individual predictions we aggregate to make a single prediction. The resulting model is an _ensemble_ model. We have seen that `Random Forests` are popular learning algorithms that combine bagging with random sampling of features, to induce diversity in decision trees and further regularization.\n",
    "\n",
    "On the other hand, boosting consists in training a sequence of decision trees which iteratively reduce the error of the previous decision tree because they are fitted on the residuals or on the gradients of the previous tree. We have focused specifically on `gradient boosting` and indicated `XGBoost` as a particularly powerful implementation of boosting + bagging.\n",
    "\n",
    "Today, we will go back to the bike data, and fit `RandomForest` and `XGBoost` models, comparing their performances to those of models fitted previously. We will implement Random Forests using `scikit-learn`, and XGBoost using the XGBoost package: https://xgboost.readthedocs.io/en/stable/ \n",
    "\n",
    "**Note**: As last week, under `nbs/class_05` you will find a notebook called `example.ipynb`, where I provide an example of how to run today's exercise on sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational remarks\n",
    "Two suggestions on how to go about this, based on where you are at regarding exercises from previous weeks.\n",
    "\n",
    "1. If you have done exercises from class 2 and 3, you will have one/two notebooks with baseline, linear, KNN, and linear regularized models, as well as records of performances (which will be handy to compare performances of our new methods). In this case, my suggestion would be to work on a new notebook where you only fit the new models, and load the performance of the old models for comparison.\n",
    "\n",
    "2. If you have not done exercises from previous classes, you have three options:\n",
    "- Work on a new notebook where you only fit the models we work on today (random forest and XGBoost). Optionally, you can \"manually\" compare the performance of your new models to plots from previous weeks\n",
    "- Work on a new notebook and also implement a couple of models from previous weeks for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today's exercise\n",
    "Work in groups on the following tasks\n",
    "\n",
    "1. Fit a `Random Forest` model to the data (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor), using cross-validation to define the best possible range of parameters\n",
    "    - There are a number of parameters that should be passed to the estimator. Carefully read the documentation, and identify a few hyperparameters you might want to manipulate\n",
    "    - Define a series of possible values for these hyperparameters, and store this information into a Python dictionary. For each hyperparameter, the dictionary should include the name of the hyperparameters (as a string) as `key`, and a list including a range of possible values as `value`\n",
    "    - Pass your estimator and the parameter grid to `GridSearchCV`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html and fit this object to your training set. If you have defined *a lot* of possible values, you can consider using `RandomizedSearchCV`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html. **Note**: you need to pass something appropriate as the value of the `scoring` argument\n",
    "    - Try to answer the following questions:\n",
    "        - What is `GridSearchCV` doing?\n",
    "        - What is the difference between `RandomizedSearchCV` and `GridSearchCV`?\n",
    "        - **Bonus question**: Given that we do have a validation set, could we do model selection without using cross-validation? Which parameter in `GridSearchCV` or `RandomizedSearchCV` would you have to change, and how, to do so?\n",
    "    - Find out which hyperparameters gave the best result\n",
    "        - **Hint**: look at the `.best_estimator_` attribute on a fitted `GridSearchCV`/`RandomizedSearchCV` and `.get_params()`\n",
    "    - Compute the performance of this model on the training, validation, and test set\n",
    "    - Compute and plot feature importances for the resulting model. You can look at the `.feature_importances_` attribute of the best estimator.\n",
    "        - **Bonus question**: which method is used by default to compute feature importances? Is any other method available in `sklearn`?\n",
    "\n",
    "2. Do the exact same things as 1., this time using `XGBRegressor` (https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor)\n",
    "    - Note: you will have to install `xgboost` (https://xgboost.readthedocs.io/en/stable/install.html) to run this (in short `pip install xgboost`)\n",
    "    - You will have to define an appropriate `scoring` parameter\n",
    "    - Parameters for grid/randomized search will be slightly different: look at the documentation for XGBRegressor, and make informed choices based on what we discussed in class\n",
    "\n",
    "3. Plot the performance of the best Random Forest models and the best XGBoost models, against models you fitted previously\n",
    "    - Which models perform best?\n",
    "    - How does the performance profile of RandomForest compare to XGBoost? Why?\n",
    "\n",
    "4. Compare feature importances across `RandomForest` and `XGBoost`: do they look similar/different?\n",
    "\n",
    "5. Overall reflection on modeling process\n",
    "    - Reflect back on your choices for previous models: should you have transformed any of the features before fitting Linear Regression, KNN, or regularized models?\n",
    "    - Can you think of ways in which our predictive problem can be made more interesting from a business perspective?\n",
    "    - Which aspect of the data are we *not* modeling, that we could/should model?\n",
    "\n",
    "\n",
    "### Extra tasks\n",
    "- Estimate a `DecisionTreeRegressor` with cross-validation, using the same logic we applied above: how does the performance of the resulting model compare to `RandomForestRegressor` and `XGBoost` regressor?\n",
    "- Go back to your fitted `GridSearchCV` or `RandomizedSearchCV`, and inspect their attributes. Can you plot performance against values of each of the parameters you are fitting? Is there any systematic pattern?\n",
    "- Reflect on hyperparameters passed to `GridSearchCV` or `RandomizedSearchCV`: how do you expect that individual manipulations of these parameters would affect the bias/variance profile of your models?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
